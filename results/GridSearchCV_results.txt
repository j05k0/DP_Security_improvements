Using /home/jozef/PycharmProjects/DP_Security_improvements/datasets/UNSW-NB15_1_chosen_features.csv dataset.

How to Tune Batch Size and Number of Epochs:
Best: 0.952700 using {'epochs': 50, 'batch_size': 40}
0.580400 (0.325155) with: {'epochs': 10, 'batch_size': 10}
0.828600 (0.153555) with: {'epochs': 50, 'batch_size': 10}
0.502800 (0.356587) with: {'epochs': 100, 'batch_size': 10}
0.582300 (0.392537) with: {'epochs': 10, 'batch_size': 20}
0.932700 (0.027206) with: {'epochs': 50, 'batch_size': 20}
0.629600 (0.382050) with: {'epochs': 100, 'batch_size': 20}
0.312000 (0.331928) with: {'epochs': 10, 'batch_size': 40}
0.952700 (0.014980) with: {'epochs': 50, 'batch_size': 40}
0.950300 (0.013026) with: {'epochs': 100, 'batch_size': 40}
0.830600 (0.125833) with: {'epochs': 10, 'batch_size': 60}
0.355500 (0.390887) with: {'epochs': 50, 'batch_size': 60}
0.853100 (0.133748) with: {'epochs': 100, 'batch_size': 60}
0.650300 (0.400442) with: {'epochs': 10, 'batch_size': 80}
0.817100 (0.145172) with: {'epochs': 50, 'batch_size': 80}
0.931600 (0.029925) with: {'epochs': 100, 'batch_size': 80}
0.651800 (0.374364) with: {'epochs': 10, 'batch_size': 100}
0.530200 (0.334568) with: {'epochs': 50, 'batch_size': 100}
0.256600 (0.254318) with: {'epochs': 100, 'batch_size': 100}
Elapsed time:  485.085193157  s.

How to Tune the Training Optimization Algorithm:
Best: 0.944700 using {'optimizer': 'Adamax'}
0.643600 (0.409083) with: {'optimizer': 'SGD'}
0.699000 (0.196899) with: {'optimizer': 'RMSprop'}
0.668700 (0.401609) with: {'optimizer': 'Adagrad'}
0.694200 (0.377344) with: {'optimizer': 'Adadelta'}
0.842100 (0.172478) with: {'optimizer': 'Adam'}
0.944700 (0.014723) with: {'optimizer': 'Adamax'}
0.937800 (0.033568) with: {'optimizer': 'Nadam'}
Elapsed time: 193.319275856 s.


